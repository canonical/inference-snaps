Inference Snaps
==========================

.. In a single sentence, say what the product is.

Inference Snaps are Generative AI models packaged and optimized for efficient inference on local hardware.

.. In a paragraph of one to three short sentences, describe what the product does.

Inference Snaps automatically detect your host machine's hardware and install runtime and model weight optimizations that best match its capabilities. This process allows for the most effective use of your silicon, whether it's a CPU, integrated or discrete GPU, or an NPU.

.. In a paragraph of one to three short sentences, describe what need the product meets.

Generative AI models perform most efficiently when they are custom-tuned for the underlying hardware. Developers and end-users often struggle to find and correctly install the complex, vendor-specific software (drivers and optimization libraries) needed for peak performance. Inference Snaps simplify this process by providing an automatic, unified detection and installation mechanism, bringing powerful local AI within easy reach.


.. Whom is the product useful for?

Inference Snaps are useful for end-users who require fast, local AI capabilities for their desktop applications, such as an IDE, a local chatbot, or a media editing tool. Additionally, they are invaluable for Application Developers who need a standardized, reliable local API to integrate high-performance AI features into their software without handling complex hardware-specific tuning.


In this documentation
---------------------

.. grid:: 1 1 2 2

   .. grid-item-card:: Tutorials
      :link: /tutorial/index
      :link-type: doc

      **Get started** - a hands-on introduction for new users.

   .. grid-item-card:: How-to guides
      :link: /how-to/index
      :link-type: doc

      **Step-by-step** guides covering key operations and common tasks

.. grid:: 1 1 2 2

   .. grid-item-card:: Reference
      :link: /reference/index
      :link-type: doc

      **Technical information** - specifications, user manuals, and architecture

   .. grid-item-card:: Explanations
      :link: /explanations/index
      :link-type: doc

      **Concepts** - discussion and clarification of key topics
   
Project and community
---------------------

The Inference Snaps project is a member of the Ubuntu family.
It is open source and warmly welcomes community projects, contributions, suggestions, fixes and constructive feedback.

- `Code of conduct <https://ubuntu.com/community/docs/ethos/code-of-conduct>`__
- :ref:`Contribute to our code <contribute-to-our-code>` 
- :ref:`Contribute to our documentation <contribute-to-our-docs>`
- :ref:`Release notes<release-notes>`


.. toctree::
   :hidden:
   :maxdepth: 1

   Tutorials </tutorial/index>
   How-to guides </how-to/index>
   Reference </reference/index>
   Explanations </explanations/index>
   contributing
   release-notes
